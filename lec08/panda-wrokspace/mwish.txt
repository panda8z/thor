right it's absolutely true like as we have more servers you know the leader is almost certainly a bottleneck cuz the leader has to process every request and it sends a copy of every request to every other server as you add more servers it just adds more work to this bottleneck node right you're not getting any benefit any performance benefit out of the added servers because they're not really doing anything they're just all happily doing whatever the leader tells them to do they're not you know subtracting from the leaders work and every single operation goes to the leader so for here you know the performance is you know inversely proportional to the number of servers that you add you add more servers this almost certainly gets lower because the leader just has more work so in this system we have the problem that more servers makes the system slower that's too bad you know these servers cost a couple thousand bucks each and you would hope that you could use them to get better performance yeah okay so the question is what if the requests may be from different clients or successive requests and same client or something what if the requests apply two totally different parts of the state so you know in a key value store maybe one of them is a put on X and the other was a put on Y like nothing to do with each other you know can we take advantage of that and the answer that is absolutely now not in this framework though or it's the center which we can take advantage of it it's very limited in this framework it could be well at a high level the leader the requests all still go through the leader and the leader still has to send it out to all the replicas and the more replicas there are the more messages the leader has to send so at a high level it's not likely to this sort of commutative or community of requests is not likely to help this situation is a fantastic thought to keep in mind though because it'll absolutely come up in other systems and people will be able to take advantage of it in other systems okay so so there's a little bit disappointing facts with server hardware wasn't helping performance so a very sort of obvious maybe the simplest way that you might be able to harness these other servers is build a system in which ya write requests all have to go through the leader but in the real world a huge number of workloads are read heavy that is there's many more reads like when you look at web pages you know it's all about reading data to produce the web page and generally there are very relatively few rights and that's true of a lot of systems so maybe we'll send rights to the leader but send weeds just to one of the replicas right just pick one of the replicas and if you have a read-only request like a get in lab 3 just send it to one of the replicas and not to the leader now if we do that we haven't helped rights much although we've gotten a lot of read workload off the leader so maybe that helps but we absolutely have made tremendous progress with reads because now the more servers we add the more clients we can support right because we're just splitting the client lead work across the different replicas so the question is if we have clients send directly to the replicas are we going to be happy yeah so up-to-date does the right is the right word in a raft like system which zookeeper is if a client sends a request to a random replica you know sure the replica you know has a copy the log in it you know it's been executing along with the leader and you know for lab 3 it's got this key value table and you know you do a get for key X and it's gonna have some four key exodus table and it can reply to you so sort of functionally the replicas got all the pieces it needs to respond to client to read requests from clients the difficulty is that there's no reason to believe that anyone replicas other than the leader is up to date because well there's a bunch of reasons why why replicas may not be up to date one of them is that they may not be in the majority that the leader was waiting for you think about what raft is doing the leader is only obliged to wait for responses to its append entries from a majority of the followers and then it can commit the operation and go on to the next operation so if this replica wasn't in the majority it may never have seen a riot it may be the network dropped it and never got it and so yeah you know the leader and you know a majority of the servers have seen the first three requests but you know this server only saw the first two it's missing B so read to be a read of you know what should be there I'll just be totally get a stale value from this one even if this replica actually saw this new log entry it might be missing the commit command you know this zookeepers app as much the same as raft it first sends out a log entry and then when the leader gets a majority of positive replies the leader sends out a notification saying yeah I'm gonna committing that log entry I may not have gotten the commit and the sort of worst case version of this although its equivalent to what I already said is that for all this client for all client to knows this replica may be partitioned from the leader or may just absolutely not be in contact with leader at all and you know the follower doesn't really have a way of knowing that actually it's just been cut off a moment ago from the leader and just not getting anything so you know without some further cleverness if we want to build a linearizable system we can't play this game of sending the attractive it as it is for performance we can't play this game at replicas sending a read request to the replicas and you shouldn't do it for lab 3 either because that 3 is also supposed to be linearizable it's any any questions about why linearize ability forbids us from having replicas serve clients ok you know that the proof is the I lost it now but the proof was that simple reading you know right one right to read one example I put on the board earlier you not a lot just you know this is not allowed to serve stale data in the linear linearizable system ok so how does how does ooh keep our deal with this zookeeper actually does you can tell from table two you look in Table two zookeepers read performance goes up dramatically as you add more servers so clearly zookeepers playing some game here which allows must be allowing it to return read only to serve read only requests from the additional servers the replicas so how does ooh keeper make this safe that's right I mean in fact it's almost not allowed to say it does need the written latest yeah the way zookeeper skins this cat is that it's not linearizable right they just like to find away this problem and say well we're not gonna be we're not going to provide linearizable reads and so therefore you don't are not obliged you know zookeepers not obliged to provide fresh data to reads it's allowed by its rules of consistency which are not linearizable to produce stale data for Wheaton's so it's sort of solved this technical problem with a kind of definitional wave of the wand by saying well we never owed you them linearizable it'll be in the first place so it's not a bug if you don't provide it and that's actually a pretty classic way to approach this to approach the sort of tension between performance and strict and strong consistency is to just not provide strong consistency nevertheless we have to keep in the back of our minds question of if the system doesn't provide linearize ability is it still going to be useful right and you do a read and you just don't get the current answer or current correct answer the most latest data like why do we believe that that's gonna produce a useful system and so let me talk about that so first of all any questions about about the basic problem zookeeper really does allow client to send read-only requests to any replica and the replica responds out of its current state and that replicate may be lagging it's log may not have the very latest log entries and so it may return stale data even though there's a more recent committed value okay so what are we left with zookeeper does actually have some it does have a set of consistency guarantees so to help people who write zookeeper based applications reason about what their applications what's actually going to happen when they run them so and these guarantees have to do with ordering as indeed linearise ability does so zookeeper does have two main guarantees that they state and this is section 2.3 one of them is it says that rights rights or linearizable now you know there are notion of linearizable isn't not quite the same in mine maybe because they're talking about rights no beads what they really mean here is that the system behaves as if even though clients might submit rights concurrently nevertheless the system behaves as if it executes the rights one at a time in some order and indeed obeys real-time ordering of right so if one right has seen to have completed before another right has issued then do keeper will indeed act as if it executed the second right after the first right so it's rights but not reads are linearizable and zookeeper isn't a strict readwrite system there are actually rights that imply reads also and for those sort of mixed rights those those you know any any operation that modifies the state is linearizable with respect to all other operations that modify the state the other guarantee of gives is that any given client its operations executes in the order specified by the client they call that FIFO client order and what this means is that if a particular client issues a right and then a read and then a read and a right or whatever that first of all the rights from that sequence fit in in the client specified order in the overall order of all clients rights so if a client says do this right then that right and the third right in the final order of rights will see the clients rates occur in the order of the client specified so for rights this is our client specified order and this is particularly you know this is a issue with the system because clients are allowed to launch asynchronous right requests that is a client can fire off a whole sequence of rights to the leader to the zookeeper leader without waiting for any of them to complete and in order resume the paper doesn't exactly say this but presumably in order for the leader to actually be able to execute the clients rights in the client specified order we're imagining I'm imagining that the client actually stamps its write requests with numbers and saying you know I'll do this one first this one second this one third and the zookeeper leader obeys that ordering right so this is particularly interesting due to these asynchronous write requests and for reads this is a little more complicated the reasons I said before don't go through the writes all go through the leader the reads just go to some replicas and so all they see is the stuff that happens to have made it to that replicas log the way we're supposed to think about the FIFO client order for reads is that if the client issues a sequence of reads again in some order the client reads one thing and then another thing and then a third thing that relative to the log on the replicas talking to those clients reads each have to occur at some particular point in the log or they need to sort of observe the state as it as the state existed at a particular point the log and furthermore that the successive reads have to observe points that don't go backwards that is if a client issues one read and then another read and the first read executes at this point in the log the second read is that you know allowed to execute it the same or later points in the log but not allowed to see a previous state by issue one read and then another read the second read has to see a state that's at least as up-to-date as the first state and that's a significant fact in that we're gonna harness when we're reasoning about how to write correct zookeeper applications and where this is especially exciting is that if the client is talking to one replica for a while and it issues some reads issue to read here and then I read there if this replica fails and the client needs to start sending its read to another replica that guaranteed this FIFO client or a guarantee still holds if the client switches to a new replica and so that means that if you know before a crash the client did a read that sort of saw state as of this point in the log that means when the clients wishes to the new replicas if it issues another read you know it's its previous read executed here if a client issues another read that read has to execute at this point or later even though it's switched replicas and you know the way this works is that each of these log entries is tagged by the leader tags it with a Z X ID which is basically just a entry number whenever a replica responds to a client read request it you know executed the request at a particular point and the replica responds with the Z X ID of the immediately preceding log entry back to the client the client remembers this was the exid of the most recent data you know is the highest z x idea i've ever seen and when the client sends a request to the same or a different replica it accompanies their request with that highest CX ID has ever seen and that tells this other replica aha you know i need to respond to that request with data that's at least relative to this point in a log and that's interesting if this you know this replicas not up this second replica is even less up to date yes was then received any of these but it receives a request from a client the client says oh gosh the last read I did executed this spot in the log and some other replica this replica needs to wait until it's gotten the entire log up to this point before it's allowed to respond to the client and I'm not sure exactly how that works but either the replicas just delays responding to the read or maybe it rejects the read and says look I just don't know the information talk to somebody else or talk to me later where's eventually the you know this replica will catch up if it's connected to the leader and then you won't be able to respond okay so reads are ordered they only go forward in time or only go forward in sort of log order and a further thing which I believe is true about reason rights is that reads and writes the FIFO client order applies to all of a clients all of a single clients requests so if I do a write from a client and I send a write to the leader it takes time before that write is sent out committed whatever so I may send it right to the leader the leader hasn't processed it or committed it yet and then I send a read to a replica the read may have to stall you know in order to guarantee FIFO client order the read and they have to stall until this client has actually seen and executed the previous the client's previous write operation so that's a consequence of this type of client order is that a reason rights are in the same order and you know the way the most obvious way to see this is if a client writes a particular piece of data you know sends a write to the leader and then immediately does a read of the same piece of data and sends that read to a replica boy it better see its own written value right if I write something to have value 17 and then I do a read and it doesn't have value 17 then that's just bizarre and it's evidence that gosh the system was not executing my requests in order because then it would have executed the write and then before the read so there must be some funny business with the replicas stalling the client must when it sends a read and say look you know I the last write request I sent a leader with ZX ID something in this replica has to wait till it sees that I'm the leader yes oh absolutely so I think what you're observing is that a read from a replica may not see the latest data so the leader may have sent out C to a majority of replicas and committed it and the majority may have executed it but if our replica that we're talking wasn't in that majority maybe this replica doesn't have the latest data and that just is the way zoo keeper works and so it does not guarantee that we'd see the latest data so if there there is a guarantee about readwrite ordering but it's only per client so if I send a write in and then I read that data the system guarantees that my bead observes my right if you send a right in and then I read the data that you wrote this isn't does not guarantee that I see your right and that's and you know that's like the foundation of how they get speed up for reads proportional to the number of replicas but I would say the system isn't linearizable and and but it is not that it has no properties then the rights are certainly many all right all rights from all clients form some one at a time sequence so that's a sense in which the rights all rights are the knee risible and each individual clients operations may be this means linearizable also it may you know this this probably means that each individual clients operations are linearize well though I'm not quite sure you know I'm actually not sure how it works but that's a reasonable supposition then when I send in an asynchronous right the system doesn't execute it yet but it does reply to me saying yeah you know I got your right and here's this yaks ID that it will have if it's committed I just like start return so that's a reasonable theory I don't actually know how it does it and then the client if it doesn't read needs to tell the replicas look you know that's right I did you know if I do a read of the data is of the operation okay so if you send a read to a replica the replicas in return you that you know really it's a read from this table is what your no way notionally what the client thinks it's doing so you client says all I want to read this row from this table the server this replica sends back its current value for that table plus the GX ID of the last operation that updated that table yeah so there's so actually I'm I'm not prepared to so the the two things that would make sense and I think either of them would be okay is the server could track this yet for every table row the ZX ID of the last right operation that touched it or it could just to all read requests returned the ZX ID as a last committed operation in its log regardless of whether that was the last operation of touch that row because all we need to do is make sure that client requests move forward in the order so we just need something to return something that's greater than or equal to the right that last touched the data that the client read all right so these are the guarantees so you know we still left with a question of whether it's possible to do reasonable programming with this set of guarantees and the answer is well this you know at a high level this is not quite as good as linearizable it's a little bit harder to reason about and there's sort of more gotchas like reads can return stale data just can't happen in a linearizable system but it's nevertheless good enough to do to make it pretty straightforward to reason about a lot of things you might want to do with zookeeper so there's a so I'm gonna try to construct an argument maybe by example of why this is not such a bad programming model one reason by the way is that there's an out there's this operation called sink which is essentially a write operation and if a client you know supposing I know that you recently wrote something you being a different client and I want to read what you wrote so I actually want fresh data I can send in one of these sink operations which is effectively well the sync operation makes its way through the system as if it were a write and you know finally showing up in the logs of the replicas that really at least the replicas that I'm talking to and then I can come back and do a read and you know I can I can tell the replica basically don't serve this read until you've seen my last sink and that actually falls out naturally from fifl client order if we if we countersink as a right then five-o client order says reads are required to see state you know there's as least as up to date is the last right from that client and so if I send in a sink and then I do read I'm the the system is obliged to give me data that's visas up to date as where my sink fell in the log order anyway if I need to read up-to-date data send in a sink then do a read and the read is guaranteed to see data as of the time the same was entered into the log so reasonably fresh so that's one out but it's an expensive one because you now we converted a cheap read into the sink operation which burned up time on the leader so it's a no-no if you don't have to do but here's a couple of examples of scenarios that the paper talks about that the reasoning about them is simplified or reasonably simple given the rules that are here so first I want to talk about the trick in section 2.3 of with the ready file where we assume there's some master and the Masters maintaining a configuration in zookeeper which is a bunch of files and zookeeper that describe you know something about our distributed system like the IP addresses of all the workers or who the master is or something so we the master who's updating this configuration and maybe a bunch of readers that need to read the current configuration and need to see it every time it changes and so the question is you know can we construct something that even though updating the configure even though the configuration is split across many files in zookeeper we can have the effect of an atomic update so that workers don't see workers that look at the configuration don't see a sort of partially updated configuration but only a completely updated that's a classic kind of thing that this configuration management that zookeeper people using zookeeper for so you know looking at the so we're copying what section 2.3 describes this will say the master is doing a bunch of rites to update the configuration and here's the order that the master for our distributed system does the rites first we're assuming there's some ready file a file named ready and if they're ready file exists then the configuration is we're allowed to read the configuration if they're ready files missing that means the configuration is being updated and we shouldn't look at it so if the master is gonna update the configuration file the very first thing it does is delete the ready file then it writes the various files very zookeeper files that hold the data for the configuration might be a lot of files nose and then when it's completely updated all the files that make up the configuration then it creates again that's ready file alright so so far the semantics are extremely straightforward this is just rights there's only rights here no reads rights are guaranteed to execute in linear order and I guess now we have to appeal the fifl client order if the master sort of tags these as oh you know I want my rights to occur in this order then the reader is obliged to enter them into the replicated log in that order and so though you know the replicas were all dutifully execute these one at a time they'll all delete the ready file then apply this right in that right and then create the ready file again so these are rights the orders straightforward for the reads though it's it's maybe a little bit maybe a little more thinking as required supposing we have some worker that needs to read the current configuration we're going to assume that this worker first checks to see whether the ready file exists it doesn't exist it's gonna you know sleep and try again so let's assume it does exist let's assume we assume that the worker checks to see if the ready file exists after it's recreated and so you know what this means now these are all right requests sent to the leader this is a read request that's just centrally whatever replica the clients talking to and then if it exists you know it's gonna read f1 and B that - the interesting thing that FIFO client order guarantees here is that if this returned true that is if the replica the client was talking to said yes that file exists then you know as were as that what that means is that at least with this setup is that as that replica that that replica had actually seen the recreate of the ready file right in order for this exist to see to see the ready file exists and because successive read operations are required to march along only forwards in the long and never backwards that means that you know if the replicas the client was talking to if it's log actually contained and then it executes this creative the ready file that means that subsequent client reads must move only forward in the sequence of rights you know that the leader put into the log so if we saw this ready that means that the read occurs that the replica excuse to read down here somewhere after the right that created the ready and that means that the reads are guaranteed to observe the effects of these rights so we do actually get some benefit here some reasoning benefit from the fact that even though it's not fully linearizable the rights are linearizable and the reads have to read sort of monotonically move forward in time to the log yes [Music] yeah so that's a great question so your question is well in all this client knows you know if this is the real scenario that the creators entered in the log and then the read arrives at the replica after that replica executed this creepy ready then everything's straightforward but there's other possibilities for how this stuff was interleaved so let's look at a much more troubling scenario so the scenario you brought up which I happen to be prepared to talk about is that yeah you know the the master at some point executed to a delete of ready or you know way back in time some previous master this master created the ready file you know after it finished updating the state I say ready for I existed for a while then some new master or this master needs to change the configurations release the ready file you know it doesn't right right and what's really troubling is that the client that needs to read this configuration might have called exists to see whether the ready file exists at this time all right and you know at this point in time yeah sure the ready file exists then time passes and the client issues the reads for the maybe the client reads the first file that makes up the configuration but maybe it you know and then it reads the second file maybe this file this read comes totally after the master has been changing the configurations so now this reader has read this damaged mix of f1 from the old configuration and f2 from the new configuration there's no reason to believe that that's going to contain anything other than broken information so so this first scenario was great the scenario is a disaster and so now we're starting to get into of like serious challenges which a carefully designed API for coordination between machines in a distributed system might actually help us solve right because like for lab 3 you know you're gonna build a put get system and a simple lab 3 style put guessed system you know it would run into this problem too and just does not have any tools to deal with it but the zookeeper API actually is more clever than this and it can cope with it and so what actually happens the way you would actually use ooh keeper is that when the client sent in this exists request to ask does this file exist and would say not only does this file exist but it would say you know tell me if it exists even set a watch on that file which means if the files ever deleted or if it doesn't exist if it's ever created but in this case if it if it is ever deleted please send me a notification and furthermore the notifications that zookeeper sends you know it's a the reader here it's only talking to some replicas this is all the replicas doing these things for it the replica guarantees to send a notification for some change to this ready file at the correct point relative to the responses to the clients reads and so what that means so you know because that the the implication of that is that in this scenario in which you know these these rights sort of fit in here in real time the guarantee is that if you ask for a watch on something and then you issue some reads if that replica you're talking to execute something that should trigger the watch in during your sequence of reads then the replica guarantees to deliver the notification about the watch before it responds to any read that came that you know saw the log after the point of the OP where the operation that triggered the watch notification executed and so this is the log on the replica and so you know if the so that you know the FIFO client ordering will say you know each client requests must fit somewhere into the log apparently these fit in here in the log what we're worried about is that this read occurs here in the log but we set up this watch and the guarantee is that will receive the note if if somebody deletes this file and we can notified then that notification will will appear at the client before a read that yields anything subsequently in the log will get the notification before we get the results of any read that's that saw something in log after the operation that produced the notification so what this means that the delete ready is gonna since we have a watch on the ready file that elite ready is going to generate a notification and that notification is guaranteed to be delivered before the read result of f2 if f2 was gonna see this second right and that means that before the reading client has finished the sequence in which it looks at the configuration it's guaranteed to see the watch notification before it sees the results of any write that happened after this delete that triggered the notification who generates the watch as well the replica let's say the client is talking to this replica and it sends in the exists request the exist room has a read only request it sends with his replica the replica is being painting on the side a table of watches saying oh you know such-and-such a client asked for a watch on this file and furthermore the watch was established at a particular Z X ID that is did a read that client did a read with the replica executed the read at this point in the log and return results are relative to this point in the log members owe that watch is relative to that point in the log and then if a delete comes in you know for every operation that there s Q so it looks in this little table it says aha you know the a there was a watch on that file and maybe it's indexed by hash of filename or something okay so the question is oh yeah this this replica has to have a watch table you know if the replica crashes and the client is officially different replica you know what about the watch table right it's already established these watch and the answer to that is that no the rep your replica crashes the new replica you switch to won't have the watch table and but the client gets a notification at the appropriate point in in the stream of responses it gets back saying oops your replica you were talking to you crashed and so the client then knows it has to completely reset up everything and so tucked away in in the examples are missing event handlers to say oh gosh you know we need to go back and we establish everything if we get a notification that our replicas crashed all right I'll continuous 